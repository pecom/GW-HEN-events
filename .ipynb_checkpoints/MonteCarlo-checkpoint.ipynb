{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy as ap\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants and other setup variables. Event rates are events/year. Spherical points should be (theta, phi)\n",
    "low_energy_rate = 500\n",
    "high_energy_rate = 70\n",
    "low_energy_resolution = (.3*np.pi/180, .3*np.pi/180)\n",
    "high_energy_resolution = (.3*np.pi/180, .3*np.pi/180)\n",
    "lisa_resolution = (1*np.pi/180, 1*np.pi/180)\n",
    "NSIDE = 128\n",
    "Npix = hp.nside2npix(NSIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo values\n",
    "# time_vals = [10, 1000, 10000, 100000, 1000000]\n",
    "# emri_array = [1, 100, 1000, 4000]\n",
    "# mbh_array = [1,2,3]\n",
    "# position_array = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample MC values\n",
    "time_vals = [500000]\n",
    "emri_array = [5000]\n",
    "mbh_array = [50]\n",
    "position_array = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff = 100000\n",
    "mbh_rate = 3\n",
    "emri_rate = 50\n",
    "position_factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time():\n",
    "    time = np.random.randint(86400*365*1000)\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random point on a sphere (uniform distribution). LISA should be fairly uniform and so should IceCube Gen II\n",
    "def random_point():\n",
    "    phi = np.random.random()*2*np.pi\n",
    "    costheta = np.random.random()*2 - 1\n",
    "    theta = np.arccos(costheta)\n",
    "    return [theta, phi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian_event(etheta, ephi, sigma, amp):\n",
    "    theta,phi=hp.pix2ang(NSIDE,np.arange(Npix))\n",
    "    return amp*np.exp(-((phi - ephi)**2+(theta - etheta)**2)/(2*sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def healpix_smooth(etheta, ephi, sig, amp):\n",
    "    pind = hp.ang2pix(NSIDE, etheta, ephi)\n",
    "    temp = np.zeros(Npix)\n",
    "    temp[pind] = amp\n",
    "    return hp.smoothing(temp, sigma=sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce redundancy! hen=True --> HEN events, hen=False --> GW events\n",
    "# category depends on hen. hen=True: category = 0 --> low energy, 1 --> high energy\n",
    "# hen=False, category = 0 --> EMRI, 1 --> MBH (doesn't matter for now)\n",
    "def general_noise(hen, category):\n",
    "    if hen:\n",
    "        if category == 0:\n",
    "            noise_val = low_energy_resolution\n",
    "        else:\n",
    "            noise_val = high_energy_resolution\n",
    "    else:\n",
    "        noise_val = lisa_resolution\n",
    "    return np.random.normal()*np.array(noise_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_event(poisson_lambda, hen, category):\n",
    "    points = []\n",
    "    noise = []\n",
    "    time = []\n",
    "    k = np.random.poisson(lam=poisson_lambda)\n",
    "    for i in range(k):\n",
    "        points.append(random_point())\n",
    "        noise.append(general_noise(hen, category))\n",
    "        time.append(add_time())\n",
    "    return [np.array(points), np.array(noise), np.array(time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hp_map(points, noise):\n",
    "    temp_map = np.zeros(Npix)\n",
    "    for i,v in enumerate(points):\n",
    "        temp_map += healpix_smooth(*v, noise[i], 1)\n",
    "    return temp_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_overlap(p1, p2, n1, n2):\n",
    "    pvec1 = hp.ang2vec(*p1)\n",
    "    pvec2 = hp.ang2vec(*p2)\n",
    "    p1_disk = hp.query_disc(256, pvec1, n1*position_factor, inclusive=True)\n",
    "    p2_disk = hp.query_disc(256, pvec2, n2*position_factor, inclusive=True)\n",
    "    overlap = np.intersect1d(p1_disk, p2_disk)\n",
    "    return len(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_overlap(t1,t2):\n",
    "    d = {}\n",
    "    for i,v in enumerate(t1):\n",
    "        a = np.where(t2 < v + time_diff)[0] \n",
    "        b = np.where(t2 > v - time_diff)[0]\n",
    "        c = np.intersect1d(a,b)\n",
    "        if len(c) > 0:\n",
    "            d[i] = c\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(e1, n1, t1, e2, n2, t2):\n",
    "    time_worthy = time_overlap(t1, t2)\n",
    "    overlap_counter = 0\n",
    "    pairs_overlap = []\n",
    "    noise_overlap = []\n",
    "    for i,v in enumerate(time_worthy):\n",
    "        pos_1 = e1[v]\n",
    "        noise_1 = np.linalg.norm(n1[v])\n",
    "        for k in time_worthy[v]:\n",
    "            pos_2 = e2[k]\n",
    "            noise_2 = np.linalg.norm(n2[k])\n",
    "            l = position_overlap(pos_1, pos_2, noise_1, noise_2)\n",
    "            if l > 0:\n",
    "                pairs_overlap.append([pos_1,pos_2])\n",
    "                noise_overlap.append([noise_1, noise_2])\n",
    "                overlap_counter += 1\n",
    "    return overlap_counter, pairs_overlap, noise_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_run():\n",
    "    low = general_event(low_energy_rate, True, 0)\n",
    "    high = general_event(high_energy_rate, True, 1)\n",
    "    emri = general_event(emri_rate, False, 0)\n",
    "    mbh = general_event(mbh_rate, False, 1)\n",
    "    l_e, le_p, le_n = overlap(*low, *emri)\n",
    "    l_m, lm_p, lm_n = overlap(*low, *mbh)\n",
    "    h_e, he_p, he_n = overlap(*high, *emri)\n",
    "    h_m, hm_p, hm_n = overlap(*high, *mbh)\n",
    "    \n",
    "    return np.array([l_e, l_m, h_e, h_m]), np.array([le_p,lm_p,he_p,hm_p]), np.array([le_n, lm_n, he_n, hm_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_big_hammer(n=100):\n",
    "    global time_diff\n",
    "    global emri_rate\n",
    "    global mbh_rate\n",
    "    global position_factor\n",
    "    with open('output/monte_run.csv', 'w') as csvfile:\n",
    "        a = csv.writer(csvfile)\n",
    "        header = ['n', 'time_diff', 'position_factor', 'emri', 'mbh', 'total_coincident']\n",
    "        a.writerow(header)\n",
    "    with open('output/total_run.csv', 'w') as csvfile:\n",
    "        b = csv.writer(csvfile)\n",
    "        header = ['n', 'time_diff', 'position_factor', 'emri', 'mbh', 'total_coincident']\n",
    "        b.writerow(header)\n",
    "    for i in time_vals:\n",
    "        time_diff = i\n",
    "        for j in emri_array:\n",
    "            emri_rate = j\n",
    "            for k in mbh_array:\n",
    "                mbh_rate = k\n",
    "                for l in position_array:\n",
    "                    lval=[]\n",
    "                    position_factor = l\n",
    "                    for m in tqdm(range(n)):\n",
    "                        monte_data,points,noise = monte_carlo_run()\n",
    "                        total = np.sum(monte_data)\n",
    "                        lval.append(total)\n",
    "                        monte_name = 'monte_big_time%i_emri%i_mbh%i_pos%i_%i_' % (i, j, k, l, m)\n",
    "                        np.save('output/' + monte_name, monte_data)\n",
    "                        if total > 0:\n",
    "                            big_map = np.zeros(Npix)\n",
    "                            for map_index in range(len(points)):\n",
    "                                temp_map = np.zeros(Npix)\n",
    "                                if monte_data[map_index] == 0:\n",
    "                                    continue\n",
    "                                noises = []\n",
    "                                pointses = []\n",
    "                                for pair_ind in range(len(noise[map_index])):\n",
    "                                    noises += noise[map_index][pair_ind]\n",
    "                                    pointses += points[map_index][pair_ind]\n",
    "                                temp_map += make_hp_map(pointses, noises)\n",
    "                                big_map += temp_map\n",
    "                                \n",
    "                                np.save('maps/'+monte_name+'map_'+str(map_index),temp_map)\n",
    "                                hp.mollview(temp_map)\n",
    "                                plt.savefig('maps/'+monte_name+'mollview_'+str(map_index))\n",
    "                                plt.close()\n",
    "                            hp.mollview(big_map)\n",
    "                            plt.savefig('maps/'+monte_name+'mollview')\n",
    "                            plt.close()\n",
    "                        with open('output/monte_run.csv', 'a') as csvfile:\n",
    "                                c = csv.writer(csvfile)\n",
    "                                data = [m,i,l,j,k,total]\n",
    "                                c.writerow(data)\n",
    "                    run_total = np.sum(lval)\n",
    "                    with open('output/total_run.csv', 'a') as csvfile:\n",
    "                        d = csv.writer(csvfile)\n",
    "                        data = [n,i,l,j,k,run_total]\n",
    "                        d.writerow(data)\n",
    "    \n",
    "                    array_name = 'lval_big_time%i_emri%i_mbh%i_pos%i_%i_' % (i, j, k, l, n)\n",
    "                    np.save('output/' + array_name, lval)\n",
    "                    plt.hist(lval);\n",
    "                    plt.savefig('images/' + array_name)\n",
    "                    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc(n=100):\n",
    "    lval = []\n",
    "    for i in tqdm(range(n)):\n",
    "        lval.append(np.sum(monte_carlo_run()))\n",
    "    return lval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a1ff1d5a7442ba9a685797ac6d1e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma is 74.079114 arcmin (0.021549 rad) \n",
      "-> fwhm is 174.442982 arcmin\n",
      "Sigma is 0.000000 arcmin (0.000000 rad) \n",
      "-> fwhm is 0.000000 arcmin\n",
      "Sigma is 148.352152 arcmin (0.043154 rad) \n",
      "-> fwhm is 349.342621 arcmin\n",
      "Sigma is 0.000000 arcmin (0.000000 rad) \n",
      "-> fwhm is 0.000000 arcmin\n",
      "Sigma is 90.949648 arcmin (0.026456 rad) \n",
      "-> fwhm is 214.170054 arcmin\n",
      "Sigma is 0.000000 arcmin (0.000000 rad) \n",
      "-> fwhm is 0.000000 arcmin\n",
      "Sigma is 56.726657 arcmin (0.016501 rad) \n",
      "-> fwhm is 133.581069 arcmin\n",
      "Sigma is 0.000000 arcmin (0.000000 rad) \n",
      "-> fwhm is 0.000000 arcmin\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "m = mc_big_hammer(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
